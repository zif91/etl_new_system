#!/bin/bash

# Ğ¡ĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ´Ğ»Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ production ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ½Ğ° ÑĞµÑ€Ğ²ĞµÑ€Ğµ
# Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°Ñ‚ÑŒ Ğ½Ğ° ÑĞµÑ€Ğ²ĞµÑ€Ğµ Ğ¿Ğ¾ÑĞ»Ğµ git push

echo "ğŸš€ Starting production deployment update..."

# ĞŸĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ² Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
cd /root/etl_new_system || {
    echo "âŒ Project directory not found!"
    exit 1
}

echo "ğŸ“¥ Pulling latest changes from GitHub..."
git pull origin main

if [ $? -ne 0 ]; then
    echo "âŒ Git pull failed!"
    exit 1
fi

echo "ğŸ›‘ Stopping current containers..."
docker compose down

echo "ğŸ”„ Rebuilding containers with latest code..."
docker compose build --no-cache

echo "ğŸš€ Starting updated containers..."
docker compose up -d

echo "â±ï¸  Waiting for services to start..."
sleep 30

echo "âœ… Checking container status..."
docker ps

echo "ğŸ¯ Checking Airflow webserver..."
curl -f http://localhost:8080/health || echo "âš ï¸  Airflow might still be starting..."

echo ""
echo "ğŸ‰ Production deployment completed!"
echo "ğŸ“Š Airflow UI: http://your-server:8080"
echo "ğŸ‘¤ Login: admin / admin"
echo ""
echo "ğŸ“‹ Next steps:"
echo "1. Check Airflow UI for DAG status"
echo "2. Enable advertising_data_pipeline DAG"
echo "3. Monitor first run for any errors"
echo "4. Check database for imported data"

echo ""
echo "ğŸ” Useful commands:"
echo "docker logs etl_new_system-airflow-webserver-1    # Check Airflow logs"
echo "docker logs etl_new_system-airflow-scheduler-1    # Check scheduler logs"
echo "docker exec -it etl_new_system-postgres-1 psql -U airflow -d airflow    # Connect to database"
